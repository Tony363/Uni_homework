{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ENGI E1006: Introduction to Computing for Engineers and Applied Scientists\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll go into a more detailed implementation of the K Nearest Neighbors algorithm using `numpy`. \n",
    "\n",
    "Recall from lecture that the goal of this algorithm is to classify an unknown data point by finding its `K` closest known data points, and taking a vote. We will implement this algorithm on the `Iris` dataset from last time.\n",
    "\n",
    "Mathematically, this algorithm is fairly straightforward. The only known calculation we need is Euclidean Distance in N dimensional space. in $R^2$, we can visualize the formula with a triangle:\n",
    "\n",
    "<img src=\"assets/euclidean_distance.png\" width=200></img>\n",
    "\n",
    "For the Iris dataset, we will be in $R^4$, and so have to use the more general formula for $R^n$:\n",
    "$$ \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2} $$\n",
    "\n",
    "Note that depending on the nature of our dataset, we could've chosen a different distance, such as Manhattan Distance:\n",
    "$$ \\sum_{i=1}^{n} |x_i - y_i| $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn # notice that scikit-learn's import name is sklearn!\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the data vertically so that the targets are a new column\n",
    "all_data = np.concatenate((iris_data.data, iris_data.target.reshape((len(iris_data.target), 1))), axis=1)\n",
    "\n",
    "# shuffle\n",
    "np.random.shuffle(all_data)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, test_percentage=.2):\n",
    "    # Split into train and test\n",
    "    trX = X[int(test_percentage*len(X)):]\n",
    "    tsX = X[:int(test_percentage*len(X))]\n",
    "\n",
    "    # separate the labels\n",
    "    trY = trX[:,-1:] # grab just the labels column\n",
    "    trY = trY.reshape(len(trY)) # reshape as vector\n",
    "    trX = trX[:,:-1] # slice out the labels column\n",
    "\n",
    "    tsY = tsX[:,-1:] # grab just the labels column\n",
    "    tsY = tsY.reshape(len(tsY)) # reshape as vector\n",
    "    tsX = tsX[:,:-1] # slice out the labels column\n",
    "    \n",
    "    return trX, trY, tsX, tsY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_labels, test_data, test_data_labels = \\\n",
    "    split_dataset(all_data, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets start implementing our function\n",
    "from statistics import mode\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def knn(data, data_labels, vector, k):\n",
    "    # data is the \"known\" points\n",
    "    # data_labels are their labels\n",
    "    # vector is an \"unknown\" point\n",
    "    \n",
    "    # preallocate distance array\n",
    "    distances = np.zeros(len(data_labels))\n",
    "\n",
    "    # calculate distances\n",
    "    for i in range(len(distances)):\n",
    "        distances[i] = sqrt(((data[i].astype(float) - vector.astype(float)) ** 2).sum())\n",
    "\n",
    "    # set labels\n",
    "    indexes = np.argsort(distances)\n",
    "\n",
    "    # take vote amongs top labels\n",
    "    to_vote = data_labels[indexes]\n",
    "    return mode(to_vote[:k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make sure this works!\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for _ in range(len(test_data_labels)):\n",
    "    predicted_label = knn(train_data, train_data_labels, test_data[_], 5)\n",
    "    real_label = test_data_labels[_]\n",
    "    \n",
    "    print('Predicted Label: {}\\t Real Label: {}'.format(\n",
    "        predicted_label,\n",
    "        real_label)\n",
    "     )\n",
    "    \n",
    "    if real_label == predicted_label:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Accuracy: {}%\".format(\n",
    "        int(correct/len(test_data_labels) * 100)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
